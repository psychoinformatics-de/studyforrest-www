var tipuesearch = {"pages":[{"title":"About StudyForrest","text":"This project is an open invitation to anyone and everyone to participate in a decentralized effort to explore the opportunities of open science in neuroimaging. It documents how much (scientific) value can be generated by open data — from the publication of scientific findings derived from this dataset, algorithms and methods evaluated on this dataset, and/or extensions of this dataset by acquisition and incorporation of new data. For questions and inquiries, please email us at info@studyforrest.org This website is open source and jointly maintained on GitHub . Contributions are always welcome. Acknowledgements # This project is collaborative effort supported by various grants and institutional funds. A grant from the German Federal Ministry of Education and Research (BMBF) funded the initial data acquisition as part of the US-German collaboration in computational neuroscience (CRCNS) project: Development of general high-dimensional models of neuronal representation spaces ( Haxby / Ramagde / Hanke ), co-funded by the BMBF and the US National Science Foundation (BMBF 01GQ1112; NSF 1129855). Development of data sharing technology used for dissemination and management of this dataset was funded by another US-German collaboration grant awarded to Halchenko and Hanke: DataLad: Converging catalogues, warehouses, and deployment logistics into a federated 'data distribution' — also co-funded by BMBF (01GQ1411) and NSF (1129855). Continued dataset maintenance and curation is supported by a third US-German collaboration grant (BMBF 01GQ1905; NSF 1912266). The Institute of Neuroscience and Medicine Brain and Behaviour (INM-7) at the Jülich Research Center supports the project with personnel and IT resources. The German federal state of Saxony-Anhalt with the The Otto-von-Guericke-University , Magdeburg, and the European Regional Development Fund (ERDF), Project: Center for Behavioral Brain Sciences provided support for data acquisition hardware and personnel. Data acquisition was, in part, funded by a grant from the German Research Foundation (DFG) awarded to Stefan Pollmann and Oliver Speck (DFG PO 548/15-1). The Leibniz Institute for Neurobiology and the Combinatorial NeuroImaging Core Facility in Magdeburg, Germany provided MR imaging expertise and access to its data acquisition instruments.","tags":"pages","url":"https://www.studyforrest.org/about.html","loc":"https://www.studyforrest.org/about.html"},{"title":"Data Access","text":"All StudyForrest data are contained in a collection of DataLad datasets hosted on GitHub , OpenNeuro , and GIN . DataLad provides fine-grained data access down to the level of individual files, and allows for tracking future updates. It is a free and open source command line tool, available for all major operating systems, and builds upon Git and git-annex to share, synchronize, and version control collections of large files. More information on DataLad and how to install it can be found in the DataLad Handbook . Get the Dataset # The dataset can be cloned by running: datalad clone https://github.com/psychoinformatics-de/studyforrest-data Once the dataset is cloned, it is a light-weight directory on your local machine. At this point, it contains only small metadata and information on the identity of the files in the dataset, but not actual content of the (sometimes large) data files. Retrieve Dataset Content # After cloning the dataset, you can retrieve file contents by running: datalad get path/to/directory/or/file This command will trigger a download of the files, directories, or subdatasets you have specified. This dataset contains other datasets, so called subdatasets . If you clone the top-level dataset, subdatasets do not yet contain metadata and information on the identity of files, but appear to be empty directories. In order to retrieve file availability metadata in subdatasets, run: datalad get -n path/to/subdataset Afterwards, you can browse the retrieved metadata to find out about subdataset contents, and retrieve individual files with datalad get . If you use datalad get path/to/subdataset , all contents of the subdataset will be downloaded at once. Terms of Use # All data are released to the public under the ODC Public Domain Dedication and Licence (PDDL) . Offering these data for download or through other means is encouraged; we only ask that you add a reference to this website. In order to provide a comprehensive overview of entities hosting these data, or any derived data artifacts, please let us know at info@studyforrest.org what data access you are providing. How to Cite # If you use these data, please follow good scientific practice and cite any relevant publications. A list of all publications can be found on the Publications Page . Hosting # We are grateful to our data hosting providers for their support, sponsored bandwidth, and storage capacity.","tags":"pages","url":"https://www.studyforrest.org/access.html","loc":"https://www.studyforrest.org/access.html"},{"title":"Copyright","text":"This page loosely follows Debian's copyright file syntax . Files: * Copyright: 2014–2021, Alex Waite, Michael Hanke, Laura Waite, Yarik Halschenko, Adina Wagner, Christian Mönch, and Stephan Heunis License: Attribution-ShareAlike 4.0 International Files: img/* Copyright: 2014–2021, Michael Hanke and Alex Waite License: ODC Public Domain Dedication and Licence (PDDL) Files: img/data/thumb_annot_confounds.png Copyright: Settings And Display Collection, Ui Interface Vectors License: CC0 1.0 Universal Public Domain Dedication Files: /img/data/thumb_annot_music.jpg Copyright: TODO: Unknown License: CC BY-SA 4.0 Files: /img/data/thumb_annot_irony.jpg Copyright: 2005, David Goehring License: Attribution 2.0 Generic (CC BY 2.0) Files: /img/data/thumb_annot_bodycontact.jpg, /img/data/thumb_annot_emotion.jpg, /img/data/thumb_annot_eyegaze.jpg, /img/data/thumb_annot_locationtime.jpg, /img/data/thumb_annot_speech.jpg Copyright: 1994, Paramount Pictures Corporation License: All Rights Reserved Files: img/logo/* License: Public Domain Files: img/logo/gin.svg Copyright: 2017, Christian Spalthoff and German Neuroinformatics Node License: Attribution 4.0 Generic (CC BY 4.0) Files: img/logo/openneuro.svg Copyright: 2018, OpenNeuro License: CC BY 4.0 Files: data/*, metadata/* Copyright: 2014–2021, Michael Hanke, Christian Mönch, and Stephan Heunis License: ODC Public Domain Dedication and Licence (PDDL) Files: img/freesurfer_parcellations.webp Copyright: 2021, Stephan Heunis License: CC BY-SA 4.0 Files: theme/* Copyright: 2013, Daan Debie; 2014–2021 Alex Waite and Michael Hanke License: MIT Notes: The theme originally derived from Daan Debie's pelican-bootstrap3 theme for Pelican . Since then, it has evolved and been almost entirely rewritten. Files: theme/fonts/cormorant-garamond* Copyright: 2015-2021, Christian Thalmann License: SIL OFL 1.1 Files: theme/fonts/fontello* Copyright: Font Awesome , Modern Pictograms , Iacopo Neri (world), Edward Boatman (beaker), Arjun Adamson (brain) License: SIL OFL 1.1 , CC BY 3.0 US (world, beaker, brain) Files: theme/fonts/open-sans* Copyright: Steve Matteson License: Apache 2.0 Files: /theme/img/run_forrest_web.jpg Copyright: 1994, Paramount Pictures Corporation License: All Rights Reserved Files: theme/js/tsl/* Copyright: 2013-2019, Tipue ; 2020, Jona Fischer and Alex Waite License: MIT Files: theme/js/xtk.js Copyright: 2012, The X Toolkit Developers License: MIT","tags":"pages","url":"https://www.studyforrest.org/copyright.html","loc":"https://www.studyforrest.org/copyright.html"},{"title":"Overview of Data Types","text":"Since its inception, the StudyForrest dataset has grown appreciably through both internal and external contributions. Made available are raw data, preprocessed data, and an extensive collection of annotations of the movie. Often, multiple data types are available for the same set of participants — for example, multiple fMRI scans of up to 10 hours total per participant. Below is an overview of all major components of the StudyForrest dataset. This includes data relating to brain structure, brain function, and movie stimulus properties. Further details for each data type can be found in the linked publications. Enable JavaScript to filter through data types. Behavior and Brain Function # A diverse set of stimulation paradigms and data acquisition setups were utilized to characterize participant's brain function on a variety of dimensions. High-res 7T fMRI on 2h Audio Movie (+Cardiac/Respiration) # Publication Explore 7T, audio, cardiac, respiration Two principle data modalities were acquired: Blood oxygenation level dependent (BOLD) fMRI scans, continuously capturing brain activity at a spatial resolution of 1.4 mm, and physiological recordings of heart beat and breathing. For technical validation, all measurements are also available for a full-length gel phantom scan. High-res 7T fMRI Listening to Music (+Cardiac/Respiration) # Publication Explore 7T, music, cardiac, respiration High-resolution, ultra high-field (7 Tesla) functional magnetic resonance imaging (fMRI) data from 20 participants that were repeatedly stimulated with a total of 25 music clips, with and without speech content, from five different genres using a slow event-related paradigm. Physiological recordings of heart beat and breathing were simultaneously recorded as well. 3T fMRI on 2h Movie, Eyegaze (+Cardiac/Respiration) # Publication Explore 3T, audio, eyegaze, cardiac, respiration Two-hour 3 Tesla fMRI acquisition while 15 participants were shown an audio-visual version of the stimulus motion picture, simultaneously recording eye gaze location, heart beat, and breathing. Retinotopic Mapping # Publication 3T, retinotopic mapping, visual cortex, eccentricity, polar angle Standard 3 mm fMRI recording of a retinotopic mapping procedure with expanding and contracting ring and rotating wedge stimuli. Resulting eccentricity and polar angle maps of the visual cortex of 15 participants are available. Higher Visual Area Localizer # Publication Explore 3T, visual area localizer, block-design, one-back task 3mm fMRI data from a standard block-design visual area localizer using greyscale images for the stimulus categories human faces, human bodies without heads, small objects, houses and outdoor scenes comprising of nature and street scenes, and phase scrambled images. Multi-res 3T/7T fMRI (0.8-3mm) on Visual Orientation # Publication 7T, 3T, visual, oriented gratings, decoding Ultra high-field 7T and 3T fMRI data recorded at 0.8 (7T-only), 1.4, 2, and 3 mm isotropic voxel size under stimulation with flickering, oriented grating stimuli. Grating orientation in the left and right visual field varied independently to enable decoding analyses. Brain Structure and Connectivity # A versatile set of structural brain images are available to provide a comprehensive in-vivo assessment of all participants' brain hardware. T1-weighted MRI # Publication 3T, T1 An image with 274 sagittal slices (FoV 191.8×256×256 mm) and an acquisition voxel size of 0.7 mm with a 384×384 in-plane reconstruction matrix (0.67 mm isotropic resolution) was recorded using a 3D turbo field echo (TFE) sequence (TR 2500 ms, inversion time (TI) 900 ms, flip angle 8 degrees, echo time (TE) 5.7 ms, bandwidth 144.4 Hz/px, Sense reduction AP 1.2, RL 2.0, scan duration 12:49 min). T2-weighted MRI # Publication 3T, T2 A 3D turbo spin-echo (TSE) sequence (TR 2500 ms, TEeff 230 ms, strong SPIR fat suppression, TSE factor 105, bandwidth 744.8 Hz/px, Sense reduction AP 2.0, RL 2.0, scan duration 7:40 min) was used to acquire an image whose geometric properties otherwise match the T1-weighted image. Susceptibility-weighted MRI # Publication 3T, SWI An image with 500 axial slices (thickness 0.35 mm, FoV 181×202×175 mm) and an in-plane acquisition voxel size of 0.7 mm reconstructed at 0.43 mm (512×512 matrix) was recorded using a 3D Presto fast field echo (FFE) sequence (TR 19 ms, TE shifted 26 ms, flip angle 10 degrees, bandwidth 217.2 Hz/px, NSA 2, Sense reduction AP 2.5, FH 2.0, scan duration 7:13 min). Diffusion-weighted MRI # Publication Explore 3T, DTI Diffusion data were recorded with a diffusion-weighted single-shot spin-echo EPI sequence (TR 9545 ms, TE 80 ms, strong SPIR fat suppression, bandwidth 2058.4 Hz/px, Sense reduction AP 2.0) using 32 diffusion-sensitizing gradient directions with b=800smm2b=800smm2 (two samples for each direction), 70 slices (thickness of 2 mm and an in-plane acquisition voxel size of 2×2 mm, reconstructed at 1.7×1.7 mm, 144×144 in-plane matrix, FoV 224×248×140 mm). Acquisition duration was 12:38 min. Angiography # Publication 7T, angiography A 3D multi-slab time-of-flight angiography was recorded at 7 Tesla for the FoV of the fMRI recording. Four slabs with 52 slices (thickness 0.3 mm) each were recorded (192×144 mm FoV, in-plane resolution 0.3×0.3 mm, GRAPPA acceleration factor 2, phase encoding direction right-to-left, 15.4% slice oversampling, 24 ms TR, 3.84 ms TE). Cortical Surface Reconstruction # Publication Explore derivative Reconstructed cortical surfaces meshes and various associated estimates were generated from the T1 and T2-weighted images of each participant using the FreeSurfer 5.3 image segmentation and reconstruction pipeline. Movie Stimulus Annotations # Annotating the content of the Forrest Gump movie, the key stimulus used in the project, is an open-ended endeavour. Its naturalistic nature is rich in diverse visual and auditory features, but also the facets of social communication enables and requires a versatile description. Cuts, Depicted Locations, and Temporal Progression # Publication movie, annotation, cut, scenes, time progression, location The exact timing of each of the 870 shots, and the depicted location after every cut with a high, medium, and low level of abstraction. Additionally, four classes are used to distinguish the differences of the depicted time between shots. Each shot is also annotated regarding the type of location (interior/exterior) and time of day. Cuts were initially detected using an automated procedure and were then later curated by hand. Speech # Publication movie, soundtrack, annotation, speech, grammar, word, dialog The exact timing of each of the more than 2,500 spoken sentences, 16,000 words (including 202 non-speech vocalizations), 66,000 phonemes, and their corresponding speaker. Additionally, every word is associated with a grammatical category, and its syntactic dependencies are defined. Portrayed Emotions # Publication movie, annotation, emotion, arousal, valence, cue Description of portrayed emotions in the movie and the audio description stimulus. The nature of an emotion is characterized with basic attributes such as onset, duration, arousal, and valence — as well as explicit emotion category labels and a record of the perceptual evidence for the presence of an emotion. Semantic Conflict # Publication movie, annotation, lies, irony Identification of episodes with portrayal of lies, irony, or sarcasm by three independent observers. Body Contact # Description movie, annotation, body parts, touch, body language A detailed description of all body contact events in the movie, including timing, actor and recipient, body parts involved, intensity and valence of the touch, and any potential audio cues. Eye Movement Labels # Publication movie, annotation, eye gaze, saccades, fixations, smooth pursuit Classification of eye movements for two groups of 15 participants watching the movie: one group inside an MRI scanner and another group in a laboratory setting. Saccades, post-saccadic oscillations, fixations, and smooth pursuit events are distinguished. Music # GitHub repository music, annotations, soundtrack Timing, artist, song title, and release year of every song in the movie's soundtrack. Low-Level Perceptual Confounds # GitHub repository movie, soundtrack, annotation Frame-wise (40 milliseconds) annotations of auditory and visual low-level confounds in the audio-description and audio-visual movie: e.g. root-mean square power (a.k.a. volume), left-right volume difference, brightness of each movie frame, and perceptual difference of each movie frame in respect to its previous frame. Participant/Acquisition Summary # The following table shows what data are available for each participant. Participant IDs are consistent across all acquisitions. Raw and preprocessed data were released over time as several datasets, and are typically available from multiple locations. If you cannot locate a dataset component you are interested in, please get in touch. Likewise, if you want to re-share data that was preprocessed in a particular way, please contact info@studyforrest.org. Participant ID 1-3 4 5 6 7-8 9-10 11-13 14-15 16-17 18 19 20 21 22-36 Structural MRI T1, T2, DWI, SWI, Angiography ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ Natural Stimulation 2h audio movie (7T, +cardiac/resp) ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ 2h audio-visual movie (3T, eyegaze, +cardiac/resp) ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ 2h audio-visual movie (in-lab eyetracking) ✓ Task fMRI Listening to music (7T, +cardiac/resp) ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ Retinotopic mapping (3T) ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ Visual area localizer (3T) ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ Flickering oriented gratings (7T @ 0.8, 1.4, 2, and 3mm) ✓ ✓ ✓ ✓ ✓ ✓ Flickering oriented gratings (3T @ 1.4, 2, and 3mm) ✓ ✓ ✓ ✓ ✓ Preprocessed Data FreeSurfer cortical surface reconstruction ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ Participant and scan-specific template MRI images (for alignment, masking, structural properties) & (non-)linear transformations between image spaces ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ Per-participant aligned fMRI data for within-subject analysis ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ Audio-visual movie fMRI aggregate ROI timeseries for Shen et al. (2013) cortex parcellation ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓","tags":"pages","url":"https://www.studyforrest.org/data.html","loc":"https://www.studyforrest.org/data.html"},{"title":"Explore","text":"The majority of demos on this page are interactive and require JavaScript to be enabled. The dataset comprises many diverse data types, ranging from brain imaging modalities to eye tracking to measurements of heart beat and respiration. This page offers a few demos to provide a glimpse into a selection of the data types and also a few quality metrics used to investigate the utility of the dataset. A comprehensive assessment can be found in the associated data papers that are available for every dataset component listed on the Data Page . An interactive walk-through tutorial is also available on Binder to provide hands-on experience with the StudyForrest dataset and DataLad: The \"Hairy\" Brain # Diffusion-weighted imaging (DWI) is a technique that can be used to visualize neural tracts or nerve fibre bundles by measuring the direction of water diffusion in brain tissue. The example figure below shows a so-called connectome — the structure of nerve fibre pathways in the brain — estimated from the DWI data of a single individual. The red horizontal lines in the center of the image show the corpus callosum , the bridge between the two brain halves. The blue vertical lines in the lower center of the image show the corticospinal tract , where the brain is connected with the nervous system in other parts of the body. The provided scans have been made with a standard clinical procedure at 2 mm spatial resolution. Left-click and drag to rotate the view, middle-click to pan, and scroll (or right-click) to zoom in and out. The Colorful World of Brain Function # One way to analyze brain function is to contrast where the brain consumes oxygen differently between particular conditions. A number of such analysis results have been published on the NeuroVault platform to enable further meta-analysis. Browse through the topics and see how individual brain areas respond differently. High-resolution 7-Tesla fMRI data on the perception of musical genres — an extension to the StudyForrest dataset. A StudyForrest extension, simultaneous fMRI and eye gaze recordings during naturalistic stimulation (poster). Is The PPA a Visual Area? BOLD responses to incidental spatial cues in naturalistic stimulation (poster). Individual face- and house-related eye movement patterns distinctively activate FFA and PPA. Processing of visual and non-visual naturalistic spatial information in the \"parahippocampal place area\" (paper in review). Brain Parcellations # High-resolution structural brain images, such as those acquired with T1- and T2-weighted MRI, can be used to reconstruct and label regions on the cortical surface as well as subcortical brain structures. Such parcellations of the brain into distinct but interacting regions support research into the fundamentals of brain organization and function. Using the FreeSurfer software package, structural data from 20 subjects were reconstructed into brain parcellations. The animation below shows this in three views for each subject, allowing for a quick quality inspection. Functional Data Quality # Since head movement during the acquisition of a functional MRI time series can be detrimental for the eventual data analysis and results, volume-to-volume head movement parameters are typically inspected as a quality indicator of fMRI data. Framewise displacement (FD) captures head movement in a single value per volume, resulting in an FD time series per functional run. Below we present interactive distribution plots of FD values for all participants over all runs of the 7T dataset. Distributions and an example time series are also presented for a single subject and a single run. 7T Audio Movie Data: 20 Subjects # 7T Audio Movie Data: 1 Subject, 8 Runs # 7T Audio Movie Data: 1 Subject, 1 Run #","tags":"pages","url":"https://www.studyforrest.org/explore.html","loc":"https://www.studyforrest.org/explore.html"},{"title":"StudyForrest","text":"What is StudyForrest ? # The human brain processes vast amounts of diverse input that are continuously gathered across the senses. However, most experiments study the brain via simplified stimuli that do little to resemble the complexity of a natural environment — a mismatch that must be addressed if we are to better understand how the brain works. This project centers around the use of the movie Forrest Gump , which provides complex sensory input that is both reproducible and is also richly laden with real-life-like content and contexts. Since its initial release, the StudyForrest dataset has grown and been extended substantially, and now encompasses many hours of fMRI scans , structural brain scans, eye-tracking data, and extensive annotations of the movie. Explore the Data Page to more closely examine the data we have available. How Can You Use It? # Neuroscience Researchers # This is a one-of-a-kind resource for studying high-level cognition in the human brain under complex, natural stimulation. Furthermore, the versatility of the provided data (some individuals have nearly ten hours of fMRI data) enables studies far beyond this main focus. This covers a vast range from studies of low-level signal properties and brain structure, to sensory integration and attentional processes, to computational modeling of representational spaces and brain area interactions. Take a look the List of Publications to get inspired. Scientific Developers # The StudyForrest project provides ideal reference datasets for brain imaging. It's a comprehensive, modular, multi-modal, real-world dataset — making it an optimal choice when benchmarking algorithms or comparing implementations across projects. Liberally licensed ( PDDL ) and hosted across many different services (OpenNeuro, GIN, etc) with fine-grained access options, the StudyForrest dataset is easily accessible and is ready to be integrated into your CI infrastructure. Everyone — and You # Not keen on brain research? This project still has something to offer to you! Our effort to analyze the structure of the movie Forrest Gump and annotate its properties greatly expands the breadth of topics that can be explored. Check out the Data Page for more specifics. What we're most interested in is applications and inquiries that we have not anticipated — both within the field of neuroscience and beyond. So please, invent applications and explore ideas you have that we aren't even aware of... and do tell us about them! How are People Using It? # The StudyForrest dataset has been used in over two dozen studies to investigate particular research questions or to validate novel tools and algorithms. […] we use fMRI activity evoked by an emotionally charged movie and continuous ratings of the perceived emotion intensity to reveal the topographic organization of affective states. — Lettieri et al., Nature Comm., 2019 […] high replicability in region-of-interest […] analyses is essential for […] biomarkers of good health or disease. […] A critical analysis of cortical parcellation protocols from FreeSurfer, BrainSuite, BrainVISA and BrainGyrusMapping revealed major limitations. — Mikhael et al., NeuroImage, 2018 […] We reveal here that hippocampal activity measured by fMRI during film watching is both sensitive and specific to event boundaries, identifying a potential mechanism whereby event boundaries shape experience by modulation of hippocampal activity. — Ben-Yakov & Henson, J Neuroscience, 2018 […] magnetic resonance advection imaging might have future potential to contribute to the modeling of the cerebrovascular system and to serve as a biomarker for cerebrovascular disease. — Voss et al., Journal of Cerebral Blood Flow & Metabolism, 2016 This also opens the door for the identification of shared and individual [brain] responses […] to assess the degree to which functional topography is shared across subjects. We posit that this technique can be adapted to examine an array of situations where group differences are the key experimental variable. — Chen et al, NIPS, 2015","tags":"pages","url":"https://www.studyforrest.org/index.html","loc":"https://www.studyforrest.org/index.html"},{"title":"Publications","text":"This page lists publications that either describe data provided by the StudyForrest project, or studies using these data or protocols. Enable JavaScript to filter through publications. Title Authors Journal Date Type Quantity and quality: Normative open-access neuroimaging databases Isherwood SJ, Bazin PL, Alkemade A, Forstmann BU PLoS ONE 2021 Study A studyforrest extension, an annotation of spoken language in the German dubbed movie \"Forrest Gump\" and its audio-description Häusler CO, Hanke M F1000Research 2021 Data A Conjugate-Gradient Approach to the Parameter Estimation Problem of Magnetic Resonance Advection Imaging Simon Hubmer, Andreas Neubauer, Ronny Ramlau, Henning U. Voss Inverse Problems in Science and Engineering 2020 Study Subject‐specific segregation of functional territories based on deep phenotyping Pinho AL, Amadon A, Fabre M, Dohmatob E, Denghien I, Torre JJ, Ginisty C, Becuwe‐Desmidt S, Roger S, Laurier L, Joly‐Testault V, Médiouni‐Cloarec G, Doublé C, Martins B, Pinel P, Eger E, Varoquaux G, Pallier C, Dehaene S, Hertz‐Pannier L, Thirion B Human Brain Mapping 2020 Citing Searching through functional space reveals distributed visual, auditory, and semantic coding in the human brain Kumar S, Ellis CT, O'Connell TP, Chun MM, Turk-Browne NB PLoS Computational Biology 2020 Study An fMRI dataset in response to \"The Grand Budapest Hotel\", a socially-rich, naturalistic movie Visconti di Oleggio Castello M, Chauhan V, Jiahui G, Gobbini MI Scientific Data 2020 Citing Individual Brain Charting dataset extension, second release of high-resolution fMRI data for cognitive mapping Pinho AL, Amadon A, Gauthier B, Clairis N, Knops A, Genon S, Dohmatob E, Torre JJ, Ginisty C, Becuwe-Desmidt S, Roger S, Lecomte Y, Berland V, Laurier L, Joly-Testault V, Médiouni-Cloarec G, Doublé C, Martins B, Salmon E, Piazza M, Melcher D, Pessiglione M, van Wassenhove V, Eger E, Varoquaux G, Dehaene S, Hertz-Pannier L, Thirion B Scientific Data 2020 Citing Two hours in Hollywood: A manually annotated ground truth data set of eye movements during movie clip watching Agtzidis I, Startsev M, Dorr M Journal of Eye Movement Research 2020 Study Leveraging shared connectivity to aggregate heterogeneous datasets into a common response space Nastase SA, Liu YF, Hillman H, Norman KA, Hasson U NeuroImage 2020 Citing REMoDNaV: robust eye-movement classification for dynamic stimulation Dar AH, Wagner AS, Hanke M Behavior Research Methods 2020 Study A naturalistic neuroimaging database for understanding the brain using ecological stimuli Aliko S, Huang J, Gheorghiu F, Meliss S, Skipper JI Scientific Data 2020 Study Using high spatial resolution fMRI to understand representation in the auditory network Moerel M, Yacoub E, Gulban OF, Lage-Castellanos A, Martino FD Progress in neurobiology 2020 Citing Movies and narratives as naturalistic stimuli in neuroimaging Jääskeläinen IP, Sams M, Glerean E, Ahveninen J NeuroImage 2020 Citing Keep it real: rethinking the primacy of experimental control in cognitive neuroscience Nastase SA, Goldstein A, Hasson U NeuroImage 2020 Citing Investigating time-varying functional connectivity derived from the Jackknife Correlation method for distinguishing between emotions in fMRI data Ghahari S, Farahani N, Fatemizadeh E, Motie Nasrabadi A Cognitive Neurodynamics 2020 Study Capturing Shared and Individual Information in fMRI Data Javier S. Turek, Cameron T. Ellis, Lena J. Skalaban, Theodore L. Willke 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2019 Study Intersubject MVPD: Empirical comparison of fMRI denoising methods for connectivity analysis Yichen Li, Rebecca Saxe, Stefano Anzellotti PLoS One 2019 Study Individual face- and house-related eye movement patterns distinctively activate FFA and PPA Wang L, Baumgartner F, Kaule FR, Hanke M, Pollmann S Nature Communications 2019 Study Intersubject MVPD: Empirical comparison of fMRI denoising methods for connectivity analysis Li Y, Saxe R, Anzellotti S PLoS ONE 2019 Study Nature abhors a paywall: How open science can realize the potential of naturalistic stimuli DuPre E, Hanke M, Poline JB NeuroImage 2019 Citing Evaluating fMRI-Based Estimation of Eye Gaze During Naturalistic Viewing Son J, Ai L, Lim R, Xu T, Colcombe S, Franco AR, Cloud J, LaConte S, Lisinski J, Klein A, Craddock RC, Milham M Cerebral Cortex (New York, NY) 2019 Citing Educational fMRI: From the Lab to the Classroom Seghier ML, Fahim MA, Habak C Frontiers in Psychology 2019 Citing Emotionotopy in the human right temporo-parietal cortex Lettieri G, Handjaras G, Ricciardi E, Leo A, Papale P, Betta M, Pietrini P, Cecchetti L Nature Communications 2019 Study A manually denoised audio-visual movie watching fMRI dataset for the studyforrest project Liu X, Zhen Z, Yang A, Bai H, Liu J Scientific Data 2019 Data A dataset of continuous affect annotations and physiological signals for emotion analysis Sharma K, Castellini C, van den Broek EL, Albu-Schaeffer A, Schwenker F Scientific Data 2019 Data A critical analysis of neuroanatomical software protocols reveals clinically relevant differences in parcellation schemes Shadia Mikhael, Corné Hoogendoorn, Maria Valdes-Hernandez, Cyril Pernet NeuroImage 2018 Study The Hippocampal Film Editor: Sensitivity and Specificity to Event Boundaries in Continuous Experience Ben-Yakov A, Henson RN The Journal of Neuroscience 2018 Study Individual Brain Charting, a high-resolution fMRI dataset for cognitive mapping Pinho AL, Amadon A, Ruest T, Fabre M, Dohmatob E, Denghien I, Ginisty C, Becuwe-Desmidt S, Roger S, Laurier L, Joly-Testault V, Médiouni-Cloarec G, Doublé C, Martins B, Pinel P, Eger E, Varoquaux G, Pallier C, Dehaene S, Hertz-Pannier L, Thirion B Scientific Data 2018 Citing Neural Responses to Naturalistic Clips of Behaving Animals in Two Different Task Contexts Nastase SA, Halchenko YO, Connolly AC, Gobbini MI, Haxby JV Frontiers in Neuroscience 2018 Study Are you thinking what I'm thinking? Synchronization of resting fMRI time-series across subjects Joshi AA, Chong M, Li J, Choi S, Leahy RM NeuroImage 2018 Study Cooperating yet distinct brain networks engaged during naturalistic paradigms: A meta-analysis of functional MRI results Bottenhorn KL, Flannery JS, Boeving ER, Riedel MC, Eickhoff SB, Sutherland MT, Laird AR Network Neuroscience 2018 Citing Teaching Computational Reproducibility for Neuroimaging Millman KJ, Brett M, Barnowski R, Poline JB Frontiers in Neuroscience 2018 Study Hypersampling of pseudo-periodic signals by analytic phase projection Voss HU Computers in biology and medicine 2018 Study Spatial band-pass filtering aids decoding musical genres from auditory cortex 7T fMRI Sengupta A, Pollmann S, Hanke M F1000Research 2018 Study The effect of acquisition resolution on orientation decoding from V1 BOLD fMRI at 7 Tesla Sengupta A, Yakupov R, Speck O, Pollmann S, Hanke M NeuroImage 2017 Study Structural Brain Correlations of Visuospatial and Visuoperceptual Tests in Parkinson's Disease Garcia-Diaz AI, Segura B, Baggio HC, Marti MJ, Valldeoriola F, Compta Y, Bargallo N, Uribe C, Campabadal A, Abos A, Junque C Journal of the International Neuropsychological Society 2017 Study Ultra high-field (7 T) multi-resolution fMRI data for orientation decoding in visual cortex Sengupta A, Yakupov R, Speck O, Pollmann S, Hanke M Data in Brief 2017 Data Functional brain segmentation using inter‐subject correlation in fMRI Kauppi J, Pajula J, Niemi J, Hari R, Tohka J Human Brain Mapping 2017 Study Electrophysiology Reveals the Neural Dynamics of Naturalistic Auditory Language Processing: Event-Related Potentials Reflect Continuous Model Updates Alday PM, Schlesewsky M, Bornkessel-Schlesewsky I eNeuro 2017 Citing Music of the 7Ts: Predicting and Decoding Multivoxel fMRI Responses with Acoustic, Schematic, and Categorical Music Features Casey MA Frontiers in Psychology 2017 Study The integration of the internal and external milieu in the insula during dynamic emotional experiences Vinh Thai Nguyen, Michael Breakspear, Xintao Hu, Christine Cong Guo NeuroImage 2016 Study Brains on Beats Umut Güçlü, Jordy Thielen, Michael Hanke, Marcel van Gerven Advances in Neural Information Processing Systems (NIPS) 2016 Study Decoding power-spectral profiles from FMRI brain activities during naturalistic auditory experience Xintao Hu, Lei Guo, Junwei Han, Tianming Liu Brain Imaging and Behavior 2016 Study Disentangling the Representation of Identity from Head View Along the Human Face Processing Pathway Guntupalli JS, Wheeler KG, Gobbini MI Cerebral Cortex (New York, NY) 2016 Study A studyforrest extension, simultaneous fMRI and eye gaze recordings during prolonged natural stimulation Hanke M, Adelhöfer N, Kottke D, Iacovella V, Sengupta A, Kaule FR, Nigbur R, Waite AQ, Baumgartner F, Stadler J Scientific Data 2016 Data An annotation of cuts, depicted locations, and temporal progression in the motion picture \"Forrest Gump\" Häusler CO, Hanke M F1000Research 2016 Data Lies, irony, and contradiction — an annotation of semantic conflict in the movie \"Forrest Gump\" Hanke M, Ibe P F1000Research 2016 Data A studyforrest extension, retinotopic mapping and localization of higher visual areas Sengupta A, Kaule FR, Guntupalli JS, Hoffmann MB, Häusler C, Stadler J, Hanke M Scientific Data 2016 Data Magnetic resonance advection imaging of cerebrovascular pulse dynamics Voss HU, Dyke JP, Tabelow K, Schiff ND, Ballon DJ Journal of Cerebral Blood Flow & Metabolism 2016 Study Data Citation in Neuroimaging: Proposed Best Practices for Data Identification and Attribution Honor LB, Haselgrove C, Frazier JA, Kennedy DN Frontiers in Neuroinformatics 2016 Citing Exploring fMRI Results Space: 31 Variants of an fMRI Analysis in AFNI, FSL, and SPM Pauli R, Bowring A, Reynolds R, Chen G, Nichols TE, Maumet C Frontiers in Neuroinformatics 2016 Citing Building a science of individual differences from fMRI Dubois J, Adolphs R Trends in cognitive sciences 2016 Citing Brain–heart interactions: challenges and opportunities with functional magnetic resonance imaging at ultra-high field Chang C, Raven EP, Duyn JH Philosophical transactions. Series A, Mathematical, physical, and engineering sciences 2016 Citing High-resolution 7-Tesla fMRI data on the perception of musical genres Michael Hanke, Richard Dinga, Christian Häusler, J. Swaroop Guntupalli, Michael Casey, Falko R. Kaule, Jörg Stadler F1000Research 2015 Data A Reduced-Dimension fMRI Shared Response Model Po-Hsuan (Cameron) Chen, Janice Chen, Yaara Yeshurun, Uri Hasson, James Haxby, Peter J. Ramadge Advances in Neural Information Processing Systems 2015 Benchmark The Detection of Emerging Trends Using Wikipedia Traffic Data and Context Networks Kämpf M, Tessenow E, Kenett DY, Kantelhardt JW PLoS ONE 2015 Citing Highest Resolution In Vivo Human Brain MRI Using Prospective Motion Correction Stucht D, Danishad KA, Schulze P, Godenschweger F, Zaitsev M, Speck O PLoS ONE 2015 Citing A communication hub for a decentralized collaboration on studying real-life cognition Hanke M, Halchenko YO F1000Research 2015 Citing Portrayed emotions in the movie \"Forrest Gump\" Labs A, Reich T, Schulenburg H, Boennen M, Mareike G, Golz M, Hartigs B, Hoffmann N, Keil S, Perlow M, Peukmann AK, Rabe LN, von Sobbe FR, Hanke M F1000Research 2015 Data A high resolution 7-Tesla resting-state fMRI test-retest dataset with cognitive and physiological measures Gorgolewski KJ, Mendes N, Wilfling D, Wladimirow E, Gauthier CJ, Bonnen T, Ruby FJ, Trampel R, Bazin PL, Cozatl R, Smallwood J, Margulies DS Scientific Data 2015 Citing Improving functional magnetic resonance imaging reproducibility Pernet C, Poline JB GigaScience 2015 Citing A high-resolution 7-Tesla fMRI dataset from complex natural stimulation with an audio movie Hanke M, Baumgartner F. J., Ibe P, Kaule F, Pollmann S, Speck O, Zinke W, Stadler J Scientific Data 2014 Data Multi-modal ultra-high resolution structural 7-Tesla MRI data repository Forstmann BU, Keuken MC, Schafer A, Bazin PL, Alkemade A, Turner R Scientific Data 2014 Citing","tags":"pages","url":"https://www.studyforrest.org/publications.html","loc":"https://www.studyforrest.org/publications.html"}]};